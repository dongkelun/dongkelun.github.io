<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">


    
  <url>
    <loc>https://dongkelun.com/2018/07/13/dbeaverConnectHive/</loc>
    <lastmod>2018-07-13T08:51:27.457Z</lastmod>
    <data>
        <display>
        <title>通过数据库客户端界面工具DBeaver连接hive</title>
        <pubTime>2018-07-12T16:00:00.000Z</pubTime>
        
        <tag>界面工具</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/17/sparkKafka/</loc>
    <lastmod>2018-07-12T13:31:38.877Z</lastmod>
    <data>
        <display>
        <title>Spark Streaming连接Kafka入门教程</title>
        <pubTime>2018-05-16T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>kafka</tag>
         
        <tag>spark streaming</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/10/HadoopException/</loc>
    <lastmod>2018-07-11T07:38:14.718Z</lastmod>
    <data>
        <display>
        <title>HDFS DataNode启动异常:/opt/jdk1.8.0_151/bin/java:权限不够</title>
        <pubTime>2018-07-09T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>ambari</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/10/ambariExceptions/</loc>
    <lastmod>2018-07-11T07:37:42.077Z</lastmod>
    <data>
        <display>
        <title>ambari 异常总结及解决办法</title>
        <pubTime>2018-07-09T16:00:00.000Z</pubTime>
        
        <tag>ambari</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/25/ambariConf/</loc>
    <lastmod>2018-07-11T07:22:29.669Z</lastmod>
    <data>
        <display>
        <title>centos7 ambari2.6.1.5+hdp2.6.4.0 大数据集群安装部署</title>
        <pubTime>2018-04-24T16:00:00.000Z</pubTime>
        
        <tag>ambari</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/hadoopClusterConf/</loc>
    <lastmod>2018-07-11T07:22:07.233Z</lastmod>
    <data>
        <display>
        <title>centos7 hadoop 集群安装配置</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
        <tag>hadoop</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/23/hadoopConf/</loc>
    <lastmod>2018-07-11T07:22:02.483Z</lastmod>
    <data>
        <display>
        <title>centos7 hadoop 单机模式安装配置</title>
        <pubTime>2018-03-22T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
        <tag>hadoop</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/24/hiveConf/</loc>
    <lastmod>2018-07-11T07:21:53.714Z</lastmod>
    <data>
        <display>
        <title>centos7 hive 单机模式安装配置</title>
        <pubTime>2018-03-23T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/20/hiveQueryException/</loc>
    <lastmod>2018-07-11T07:21:48.311Z</lastmod>
    <data>
        <display>
        <title>hive查询报错:java.io.IOException:org.apache.parquet.io.ParquetDecodingException</title>
        <pubTime>2018-05-19T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>hive</tag>
         
        <tag>异常解决</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/21/kafkaConf/</loc>
    <lastmod>2018-07-11T07:21:38.800Z</lastmod>
    <data>
        <display>
        <title>Kafka安装启动入门教程</title>
        <pubTime>2018-05-20T16:00:00.000Z</pubTime>
        
        <tag>centos7</tag>
         
        <tag>kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/25/KafkaUV/</loc>
    <lastmod>2018-07-11T07:21:31.453Z</lastmod>
    <data>
        <display>
        <title>SparkStreaming+Kafka 实现统计基于缓存的实时uv</title>
        <pubTime>2018-06-24T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>SparkStreaming</tag>
         
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/23/oggOracle2Kafka/</loc>
    <lastmod>2018-07-11T07:21:12.913Z</lastmod>
    <data>
        <display>
        <title>利用ogg实现oracle到kafka的增量数据实时同步</title>
        <pubTime>2018-05-22T16:00:00.000Z</pubTime>
        
        <tag>kafka</tag>
         
        <tag>ogg</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/05/oracleConf/</loc>
    <lastmod>2018-07-11T07:21:07.315Z</lastmod>
    <data>
        <display>
        <title>centos7 安装oracle11</title>
        <pubTime>2018-05-04T16:00:00.000Z</pubTime>
        
        <tag>centos7</tag>
         
        <tag>oracle</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/11/rdd2df/</loc>
    <lastmod>2018-07-11T07:21:01.475Z</lastmod>
    <data>
        <display>
        <title>旧版spark（1.6版本） 将rdd动态转为dataframe</title>
        <pubTime>2018-05-10T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>DataFrame</tag>
         
        <tag>Rdd</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/09/sparkArchitecturePrinciples/</loc>
    <lastmod>2018-07-11T07:20:39.026Z</lastmod>
    <data>
        <display>
        <title>Spark架构原理</title>
        <pubTime>2018-06-08T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>原理</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/28/sparkGetPartitionId/</loc>
    <lastmod>2018-07-11T07:20:16.259Z</lastmod>
    <data>
        <display>
        <title>Spark获取当前分区的partitionId</title>
        <pubTime>2018-06-27T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/30/sparkGZ/</loc>
    <lastmod>2018-07-11T07:20:09.688Z</lastmod>
    <data>
        <display>
        <title>Spark读取压缩文件</title>
        <pubTime>2018-05-29T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>压缩文件</tag>
         
        <tag>编码问题</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/25/sparkHive/</loc>
    <lastmod>2018-07-11T07:19:29.259Z</lastmod>
    <data>
        <display>
        <title>spark连接hive（spark-shell和eclipse两种方式）</title>
        <pubTime>2018-03-24T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/21/sparkMysql/</loc>
    <lastmod>2018-07-11T07:19:06.159Z</lastmod>
    <data>
        <display>
        <title>Spark Sql 连接mysql</title>
        <pubTime>2018-03-20T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/11/sparkNewUV/</loc>
    <lastmod>2018-07-11T07:19:00.288Z</lastmod>
    <data>
        <display>
        <title>spark 统计每天新增用户数</title>
        <pubTime>2018-04-10T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>scala</tag>
         
        <tag>面试题</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/16/sparkOnYarnConf/</loc>
    <lastmod>2018-07-11T07:18:54.184Z</lastmod>
    <data>
        <display>
        <title>spark on yarn 配置及异常解决</title>
        <pubTime>2018-04-15T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>yarn</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/20/sparkStreamingOffsetOnlyOnce/</loc>
    <lastmod>2018-07-11T07:18:48.561Z</lastmod>
    <data>
        <display>
        <title>Spark Streamming+Kafka提交offset实现有且仅有一次</title>
        <pubTime>2018-06-19T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>Kafka</tag>
         
        <tag>Spark Streamming</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/06/sparkSubmitException1/</loc>
    <lastmod>2018-07-11T07:18:31.520Z</lastmod>
    <data>
        <display>
        <title>spark-submit报错:Application application_1529650293575_0148 finished with failed status</title>
        <pubTime>2018-07-05T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/sshConf/</loc>
    <lastmod>2018-07-11T07:18:08.468Z</lastmod>
    <data>
        <display>
        <title>linux ssh 免密登录</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>linux</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/14/updateStateBykeyWordCount/</loc>
    <lastmod>2018-07-11T07:17:19.109Z</lastmod>
    <data>
        <display>
        <title>SparkStreaming+Kafka 实现基于缓存的实时wordcount程序</title>
        <pubTime>2018-06-13T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>SparkStreaming</tag>
         
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/16/vmwareSetFixIP/</loc>
    <lastmod>2018-07-11T07:17:01.257Z</lastmod>
    <data>
        <display>
        <title>vmware centos7 设置固定ip</title>
        <pubTime>2018-01-15T16:00:00.000Z</pubTime>
        
        <tag>vmware</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/15/winSparkConf/</loc>
    <lastmod>2018-07-11T07:16:32.414Z</lastmod>
    <data>
        <display>
        <title>win10 spark+scala+eclipse+sbt 安装配置</title>
        <pubTime>2018-03-14T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
  <url>
    <loc>https://dongkelun.com/2018/03/29/scalaUnderscoreUseGuide/</loc>
    <lastmod>2018-07-05T09:02:47.899Z</lastmod>
    <data>
        <display>
        <title>scala 下划线使用指南</title>
        <pubTime>2018-03-28T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
        <tag>转载</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/centosInitialConf/</loc>
    <lastmod>2018-07-05T09:02:38.485Z</lastmod>
    <data>
        <display>
        <title>CentOS 初始环境配置</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/22/ibatisTransaction/</loc>
    <lastmod>2018-07-05T09:02:31.561Z</lastmod>
    <data>
        <display>
        <title>ibatis 事务 java</title>
        <pubTime>2018-01-21T16:00:00.000Z</pubTime>
        
        <tag>ibatis</tag>
         
        <tag>java</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/22/mysqlTimeZoneErr/</loc>
    <lastmod>2018-07-05T09:02:26.200Z</lastmod>
    <data>
        <display>
        <title>连接mysql报错：Exception in thread "main" java.sql.SQLException:The server time zone value 'EDT' is unrecognized or represents more than one time zone</title>
        <pubTime>2018-03-21T16:00:00.000Z</pubTime>
        
        <tag>mysql</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/17/networkIsUnreachable/</loc>
    <lastmod>2018-07-05T09:02:19.842Z</lastmod>
    <data>
        <display>
        <title>network is unreachable centos无法连接外网（或unknown host baidu.com）</title>
        <pubTime>2018-01-16T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/09/redisClusterDeployment/</loc>
    <lastmod>2018-07-05T09:02:11.145Z</lastmod>
    <data>
        <display>
        <title>Redis Cluster 安装配置</title>
        <pubTime>2018-01-08T16:00:00.000Z</pubTime>
        
        <tag>redis</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/01/scalaMapAdd/</loc>
    <lastmod>2018-07-05T09:02:05.519Z</lastmod>
    <data>
        <display>
        <title>scala 两个map合并，key相同时value相加</title>
        <pubTime>2018-03-31T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/23/sparkBasicConcept/</loc>
    <lastmod>2018-07-05T09:01:54.810Z</lastmod>
    <data>
        <display>
        <title>spark基本概念（便于自己随时查阅--摘自Spark快速大数据分析）</title>
        <pubTime>2018-01-22T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/09/sparkMlLinearRegressionUsing/</loc>
    <lastmod>2018-07-05T09:01:44.010Z</lastmod>
    <data>
        <display>
        <title>spark ML算法之线性回归使用</title>
        <pubTime>2018-04-08T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>ml</tag>
         
        <tag>算法</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/27/dfChangeAllColDatatypes/</loc>
    <lastmod>2018-07-05T09:01:33.582Z</lastmod>
    <data>
        <display>
        <title>spark 将DataFrame所有的列类型改为double</title>
        <pubTime>2018-04-26T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/06/sparkSubmitException/</loc>
    <lastmod>2018-07-05T09:01:24.922Z</lastmod>
    <data>
        <display>
        <title>spark-submit报错:Exception in thread "main" java.sql.SQLException:No suitable driver</title>
        <pubTime>2018-05-05T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/17/sparkMlFeatureProcessing1/</loc>
    <lastmod>2018-07-05T09:01:14.056Z</lastmod>
    <data>
        <display>
        <title>spark ML之特征处理（1）</title>
        <pubTime>2018-05-16T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>ml</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/27/sparkDelFirstNLines/</loc>
    <lastmod>2018-07-05T08:59:46.018Z</lastmod>
    <data>
        <display>
        <title>如何解决spark开发中遇到需要去掉文件前几行数据的问题</title>
        <pubTime>2018-05-26T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>rdd</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/01/scalaDate/</loc>
    <lastmod>2018-07-05T08:59:40.569Z</lastmod>
    <data>
        <display>
        <title>Scala日期操作</title>
        <pubTime>2018-05-31T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
        <tag>日期</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/03/sparkCacheAndPersist/</loc>
    <lastmod>2018-07-05T08:59:32.068Z</lastmod>
    <data>
        <display>
        <title>Spark 持久化（cache和persist的区别）</title>
        <pubTime>2018-06-02T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>持久化</tag>
         
        <tag>cache</tag>
         
        <tag>persist</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/21/modifyKafkaOffsetTime/</loc>
    <lastmod>2018-07-05T08:58:47.676Z</lastmod>
    <data>
        <display>
        <title>通过offsets.retention.minutes设置kafka offset的过期时间</title>
        <pubTime>2018-06-20T16:00:00.000Z</pubTime>
        
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/19/sparkSubmitKafka/</loc>
    <lastmod>2018-07-05T08:58:11.181Z</lastmod>
    <data>
        <display>
        <title>spark-submit提交Spark Streamming+Kafka程序</title>
        <pubTime>2018-06-18T16:00:00.000Z</pubTime>
        
        <tag>spark</tag>
         
        <tag>Kafka</tag>
         
        <tag>spark-submit</tag>
         
        <tag>Spark Streamming</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/04/sparkDfSortDesc/</loc>
    <lastmod>2018-07-05T08:57:30.982Z</lastmod>
    <data>
        <display>
        <title>Spark DataFrame按某列降序排序</title>
        <pubTime>2018-07-03T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
    
    
    
</urlset>