<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">


    
  <url>
    <loc>https://dongkelun.com/2018/12/26/sparkSqlOptimize/</loc>
    <lastmod>2018-12-27T03:42:05.057Z</lastmod>
    <data>
        <display>
        <title>Spark SQL 优化笔记</title>
        <pubTime>2018-12-25T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>SQL</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/11/20/getAllHDFSFileNames/</loc>
    <lastmod>2018-12-26T09:23:55.242Z</lastmod>
    <data>
        <display>
        <title>打印（获取）HDFS路径下所有的文件名（包括子目录下的）</title>
        <pubTime>2018-11-19T16:00:00.000Z</pubTime>
        
        <tag>Scala</tag>
         
        <tag>HDFS</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
  <url>
    <loc>https://dongkelun.com/2018/12/14/scalaLearningNotes/</loc>
    <lastmod>2018-12-14T07:57:32.018Z</lastmod>
    <data>
        <display>
        <title>Scala学习笔记</title>
        <pubTime>2018-12-13T16:00:00.000Z</pubTime>
        
        <tag>Scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/05/oracleConf/</loc>
    <lastmod>2018-12-09T14:23:59.217Z</lastmod>
    <data>
        <display>
        <title>Centos7 安装oracle11</title>
        <pubTime>2018-05-04T16:00:00.000Z</pubTime>
        
        <tag>centos7</tag>
         
        <tag>oracle</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/07/hiveBucketTable/</loc>
    <lastmod>2018-12-09T04:24:43.422Z</lastmod>
    <data>
        <display>
        <title>Hive分桶表学习总结</title>
        <pubTime>2018-12-06T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
        <tag>bucket</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/17/sparkMlFeatureProcessing1/</loc>
    <lastmod>2018-12-07T15:35:20.561Z</lastmod>
    <data>
        <display>
        <title>spark ML之特征处理（1）</title>
        <pubTime>2018-05-16T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>ml</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/03/sparkCacheAndPersist/</loc>
    <lastmod>2018-12-07T08:40:21.640Z</lastmod>
    <data>
        <display>
        <title>Spark 持久化（cache和persist的区别）</title>
        <pubTime>2018-06-02T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>持久化</tag>
         
        <tag>cache</tag>
         
        <tag>persist</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/06/sparkSubmitException/</loc>
    <lastmod>2018-12-06T14:46:46.148Z</lastmod>
    <data>
        <display>
        <title>spark-submit报错:Exception in thread "main" java.sql.SQLException:No suitable driver</title>
        <pubTime>2018-05-05T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
    
  <url>
    <loc>https://dongkelun.com/2018/05/11/rdd2df/</loc>
    <lastmod>2018-12-05T12:53:10.662Z</lastmod>
    <data>
        <display>
        <title>旧版Spark（1.6版本） 将RDD动态转为DataFrame</title>
        <pubTime>2018-05-10T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
        <tag>Rdd</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/27/dfChangeAllColDatatypes/</loc>
    <lastmod>2018-12-05T03:20:42.111Z</lastmod>
    <data>
        <display>
        <title>Spark 将DataFrame所有的列类型改为double</title>
        <pubTime>2018-04-26T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/04/sparkHivePatition/</loc>
    <lastmod>2018-12-04T13:51:30.896Z</lastmod>
    <data>
        <display>
        <title>Spark操作Hive分区表</title>
        <pubTime>2018-12-03T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hive</tag>
         
        <tag>Partition</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/25/sparkHive/</loc>
    <lastmod>2018-12-04T13:49:30.472Z</lastmod>
    <data>
        <display>
        <title>Spark连接Hive（spark-shell和Eclipse两种方式）</title>
        <pubTime>2018-03-24T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/02/hivePartitionTable/</loc>
    <lastmod>2018-12-04T03:58:04.747Z</lastmod>
    <data>
        <display>
        <title>Hive分区表学习总结</title>
        <pubTime>2018-12-01T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
        <tag>Partition</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/03/hiveInternalAndExternalTables/</loc>
    <lastmod>2018-12-03T08:42:49.378Z</lastmod>
    <data>
        <display>
        <title>Hive内部表和外部表</title>
        <pubTime>2018-12-02T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/09/sparkMlLinearRegressionUsing/</loc>
    <lastmod>2018-12-02T14:20:36.911Z</lastmod>
    <data>
        <display>
        <title>spark ML算法之线性回归使用</title>
        <pubTime>2018-04-08T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>ml</tag>
         
        <tag>算法</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/06/sparkSubmitException1/</loc>
    <lastmod>2018-11-30T01:08:49.533Z</lastmod>
    <data>
        <display>
        <title>spark-submit报错:Application application_1529650293575_0148 finished with failed status</title>
        <pubTime>2018-07-05T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/11/27/echartsChinaMap/</loc>
    <lastmod>2018-11-29T03:47:52.597Z</lastmod>
    <data>
        <display>
        <title>Echarts中国地图三级钻取</title>
        <pubTime>2018-11-26T16:00:00.000Z</pubTime>
        
        <tag>Echarts</tag>
         
        <tag>front-end</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/25/ambariConf/</loc>
    <lastmod>2018-11-28T02:01:58.362Z</lastmod>
    <data>
        <display>
        <title>centos7 ambari2.6.1.5+hdp2.6.4.0 大数据集群安装部署</title>
        <pubTime>2018-04-24T16:00:00.000Z</pubTime>
        
        <tag>ambari</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/11/19/vueCliCreateProject/</loc>
    <lastmod>2018-11-19T10:12:03.722Z</lastmod>
    <data>
        <display>
        <title>通过Vue CLI 快速创建Vue项目并部署到tomcat</title>
        <pubTime>2018-11-18T16:00:00.000Z</pubTime>
        
        <tag>Vue</tag>
         
        <tag>Vue CLI</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/11/16/sparkSubmitLogLevel/</loc>
    <lastmod>2018-11-16T07:15:27.094Z</lastmod>
    <data>
        <display>
        <title>Spark 通过 spark-submit 设置日志级别</title>
        <pubTime>2018-11-15T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/23/hadoopConf/</loc>
    <lastmod>2018-11-16T02:39:39.659Z</lastmod>
    <data>
        <display>
        <title>centos7 hadoop 单机模式安装配置</title>
        <pubTime>2018-03-22T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/hadoopClusterConf/</loc>
    <lastmod>2018-11-16T02:39:21.574Z</lastmod>
    <data>
        <display>
        <title>centos7 hadoop 集群安装配置</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/17/sparkKafka/</loc>
    <lastmod>2018-11-16T02:33:19.468Z</lastmod>
    <data>
        <display>
        <title>Spark Streaming连接Kafka入门教程</title>
        <pubTime>2018-05-16T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Kafka</tag>
         
        <tag>Spark Streaming</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/19/sparkSubmitKafka/</loc>
    <lastmod>2018-11-16T02:30:08.086Z</lastmod>
    <data>
        <display>
        <title>spark-submit提交Spark Streaming+Kafka程序</title>
        <pubTime>2018-06-18T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Kafka</tag>
         
        <tag>Spark Streaming</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/20/sparkStreamingOffsetOnlyOnce/</loc>
    <lastmod>2018-11-16T02:29:43.663Z</lastmod>
    <data>
        <display>
        <title>Spark Streaming+Kafka提交offset实现有且仅有一次(exactly-once)</title>
        <pubTime>2018-06-19T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Kafka</tag>
         
        <tag>Spark Streaming</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/21/kafkaConf/</loc>
    <lastmod>2018-11-16T02:23:47.267Z</lastmod>
    <data>
        <display>
        <title>Kafka安装启动入门教程</title>
        <pubTime>2018-05-20T16:00:00.000Z</pubTime>
        
        <tag>Kafka</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/23/oggOracle2Kafka/</loc>
    <lastmod>2018-11-16T02:23:28.813Z</lastmod>
    <data>
        <display>
        <title>利用ogg实现oracle到kafka的增量数据实时同步</title>
        <pubTime>2018-05-22T16:00:00.000Z</pubTime>
        
        <tag>Kafka</tag>
         
        <tag>ogg</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/30/sparkGZ/</loc>
    <lastmod>2018-11-16T02:19:14.111Z</lastmod>
    <data>
        <display>
        <title>Spark读取压缩文件</title>
        <pubTime>2018-05-29T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>压缩文件</tag>
         
        <tag>编码问题</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/09/sparkArchitecturePrinciples/</loc>
    <lastmod>2018-11-16T02:14:49.453Z</lastmod>
    <data>
        <display>
        <title>Spark架构原理</title>
        <pubTime>2018-06-08T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>原理</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/20/hiveQueryException/</loc>
    <lastmod>2018-11-16T02:10:59.206Z</lastmod>
    <data>
        <display>
        <title>hive查询报错:java.io.IOException:org.apache.parquet.io.ParquetDecodingException</title>
        <pubTime>2018-05-19T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>hive</tag>
         
        <tag>异常解决</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/14/updateStateBykeyWordCount/</loc>
    <lastmod>2018-11-16T02:10:39.118Z</lastmod>
    <data>
        <display>
        <title>SparkStreaming+Kafka 实现基于缓存的实时wordcount程序</title>
        <pubTime>2018-06-13T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>SparkStreaming</tag>
         
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/27/sparkDelFirstNLines/</loc>
    <lastmod>2018-11-16T01:54:22.727Z</lastmod>
    <data>
        <display>
        <title>如何解决Spark开发中遇到需要去掉文件前几行数据的问题</title>
        <pubTime>2018-05-26T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>rdd</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/16/sparkOnYarnConf/</loc>
    <lastmod>2018-11-16T01:47:42.892Z</lastmod>
    <data>
        <display>
        <title>spark on yarn 配置及异常解决</title>
        <pubTime>2018-04-15T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>yarn</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/11/sparkNewUV/</loc>
    <lastmod>2018-11-16T01:47:36.384Z</lastmod>
    <data>
        <display>
        <title>Spark 统计每天新增用户数</title>
        <pubTime>2018-04-10T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Scala</tag>
         
        <tag>面试题</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/23/sparkBasicConcept/</loc>
    <lastmod>2018-11-16T01:47:04.768Z</lastmod>
    <data>
        <display>
        <title>Spark基本概念（便于自己随时查阅--摘自Spark快速大数据分析）</title>
        <pubTime>2018-01-22T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/15/winSparkConf/</loc>
    <lastmod>2018-11-16T01:43:49.126Z</lastmod>
    <data>
        <display>
        <title>win10 spark+scala+eclipse+sbt 安装配置</title>
        <pubTime>2018-03-14T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/21/sparkMysql/</loc>
    <lastmod>2018-11-16T01:43:35.705Z</lastmod>
    <data>
        <display>
        <title>Spark Sql 连接mysql</title>
        <pubTime>2018-03-20T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/25/KafkaUV/</loc>
    <lastmod>2018-11-16T01:40:44.311Z</lastmod>
    <data>
        <display>
        <title>SparkStreaming+Kafka 实现统计基于缓存的实时uv</title>
        <pubTime>2018-06-24T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>SparkStreaming</tag>
         
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/10/23/tomcatConf/</loc>
    <lastmod>2018-10-24T06:01:48.159Z</lastmod>
    <data>
        <display>
        <title>Centos7 Tomcat9 安装笔记</title>
        <pubTime>2018-10-22T16:00:00.000Z</pubTime>
        
        <tag>tomcat</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
    
    
  <url>
    <loc>https://dongkelun.com/2018/09/02/sparkMapPartitions/</loc>
    <lastmod>2018-09-03T12:11:42.103Z</lastmod>
    <data>
        <display>
        <title>Spark性能优化：基于分区进行操作</title>
        <pubTime>2018-09-01T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Partitions</tag>
         
        <tag>性能优化</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/27/sparkOracle2Hive/</loc>
    <lastmod>2018-08-27T09:02:10.820Z</lastmod>
    <data>
        <display>
        <title>利用Spark实现Oracle到Hive的历史数据同步</title>
        <pubTime>2018-08-26T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
        <tag>Hive</tag>
         
        <tag>Oracle</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/20/sparkDfAddComments/</loc>
    <lastmod>2018-08-23T09:06:13.584Z</lastmod>
    <data>
        <display>
        <title>Spark通过修改DataFrame的schema给表字段添加注释</title>
        <pubTime>2018-08-19T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/13/sparkDefaultPartitionNums/</loc>
    <lastmod>2018-08-22T12:17:08.680Z</lastmod>
    <data>
        <display>
        <title>Spark 创建RDD、DataFrame各种情况的默认分区数</title>
        <pubTime>2018-08-12T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
        <tag>Partition</tag>
         
        <tag>Rdd</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/14/sparkEmptyDataFrame/</loc>
    <lastmod>2018-08-14T13:18:19.421Z</lastmod>
    <data>
        <display>
        <title>Spark创建空的DataFrame</title>
        <pubTime>2018-08-13T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/28/sparkGetPartitionId/</loc>
    <lastmod>2018-08-13T06:28:30.144Z</lastmod>
    <data>
        <display>
        <title>Spark获取当前分区的partitionId</title>
        <pubTime>2018-06-27T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Partition</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/02/sparkUDF/</loc>
    <lastmod>2018-08-02T15:11:53.338Z</lastmod>
    <data>
        <display>
        <title>Spark UDF使用详解及代码示例</title>
        <pubTime>2018-08-01T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
        <tag>UDF</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/13/dbeaverConnectHive/</loc>
    <lastmod>2018-07-14T01:49:37.663Z</lastmod>
    <data>
        <display>
        <title>通过数据库客户端界面工具DBeaver连接Hive</title>
        <pubTime>2018-07-12T16:00:00.000Z</pubTime>
        
        <tag>界面工具</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/10/HadoopException/</loc>
    <lastmod>2018-07-11T07:38:14.718Z</lastmod>
    <data>
        <display>
        <title>HDFS DataNode启动异常:/opt/jdk1.8.0_151/bin/java:权限不够</title>
        <pubTime>2018-07-09T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>ambari</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/10/ambariExceptions/</loc>
    <lastmod>2018-07-11T07:37:42.078Z</lastmod>
    <data>
        <display>
        <title>ambari 异常总结及解决办法</title>
        <pubTime>2018-07-09T16:00:00.000Z</pubTime>
        
        <tag>ambari</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/24/hiveConf/</loc>
    <lastmod>2018-07-11T07:21:53.715Z</lastmod>
    <data>
        <display>
        <title>centos7 hive 单机模式安装配置</title>
        <pubTime>2018-03-23T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/sshConf/</loc>
    <lastmod>2018-07-11T07:18:08.469Z</lastmod>
    <data>
        <display>
        <title>linux ssh 免密登录</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>linux</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/16/vmwareSetFixIP/</loc>
    <lastmod>2018-07-11T07:17:01.257Z</lastmod>
    <data>
        <display>
        <title>vmware centos7 设置固定ip</title>
        <pubTime>2018-01-15T16:00:00.000Z</pubTime>
        
        <tag>vmware</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/29/scalaUnderscoreUseGuide/</loc>
    <lastmod>2018-07-05T09:02:47.900Z</lastmod>
    <data>
        <display>
        <title>scala 下划线使用指南</title>
        <pubTime>2018-03-28T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
        <tag>转载</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/centosInitialConf/</loc>
    <lastmod>2018-07-05T09:02:38.485Z</lastmod>
    <data>
        <display>
        <title>CentOS 初始环境配置</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/22/ibatisTransaction/</loc>
    <lastmod>2018-07-05T09:02:31.562Z</lastmod>
    <data>
        <display>
        <title>ibatis 事务 java</title>
        <pubTime>2018-01-21T16:00:00.000Z</pubTime>
        
        <tag>ibatis</tag>
         
        <tag>java</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/22/mysqlTimeZoneErr/</loc>
    <lastmod>2018-07-05T09:02:26.200Z</lastmod>
    <data>
        <display>
        <title>连接mysql报错：Exception in thread "main" java.sql.SQLException:The server time zone value 'EDT' is unrecognized or represents more than one time zone</title>
        <pubTime>2018-03-21T16:00:00.000Z</pubTime>
        
        <tag>mysql</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/17/networkIsUnreachable/</loc>
    <lastmod>2018-07-05T09:02:19.842Z</lastmod>
    <data>
        <display>
        <title>network is unreachable centos无法连接外网（或unknown host baidu.com）</title>
        <pubTime>2018-01-16T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/09/redisClusterDeployment/</loc>
    <lastmod>2018-07-05T09:02:11.145Z</lastmod>
    <data>
        <display>
        <title>Redis Cluster 安装配置</title>
        <pubTime>2018-01-08T16:00:00.000Z</pubTime>
        
        <tag>redis</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/01/scalaMapAdd/</loc>
    <lastmod>2018-07-05T09:02:05.520Z</lastmod>
    <data>
        <display>
        <title>scala 两个map合并，key相同时value相加</title>
        <pubTime>2018-03-31T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/01/scalaDate/</loc>
    <lastmod>2018-07-05T08:59:40.569Z</lastmod>
    <data>
        <display>
        <title>Scala日期操作</title>
        <pubTime>2018-05-31T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
        <tag>日期</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/21/modifyKafkaOffsetTime/</loc>
    <lastmod>2018-07-05T08:58:47.677Z</lastmod>
    <data>
        <display>
        <title>通过offsets.retention.minutes设置kafka offset的过期时间</title>
        <pubTime>2018-06-20T16:00:00.000Z</pubTime>
        
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/04/sparkDfSortDesc/</loc>
    <lastmod>2018-07-05T08:57:30.983Z</lastmod>
    <data>
        <display>
        <title>Spark DataFrame按某列降序排序</title>
        <pubTime>2018-07-03T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
    
</urlset>