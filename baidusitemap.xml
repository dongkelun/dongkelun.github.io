<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">


    
  <url>
    <loc>https://dongkelun.com/2022/10/01/flinkS3/</loc>
    <lastmod>2022-10-01T07:19:08.057Z</lastmod>
    <data>
        <display>
        <title>Flink 读写 Ceph S3入门学习总结</title>
        <pubTime>2022-09-30T16:00:00.000Z</pubTime>
        
        <tag>Ceph</tag>
         
        <tag>S3</tag>
         
        <tag>Flink</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/09/30/saprkS3/</loc>
    <lastmod>2022-09-29T11:46:52.963Z</lastmod>
    <data>
        <display>
        <title>Spark 读写 Ceph S3入门学习总结</title>
        <pubTime>2022-09-29T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Ceph</tag>
         
        <tag>S3</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/09/29/cephInstallConf/</loc>
    <lastmod>2022-09-29T06:06:19.906Z</lastmod>
    <data>
        <display>
        <title>Ceph分布式集群安装配置</title>
        <pubTime>2022-09-28T16:00:00.000Z</pubTime>
        
        <tag>Ceph</tag>
         
        <tag>S3</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
  <url>
    <loc>https://dongkelun.com/2019/02/18/vueEchartsMap/</loc>
    <lastmod>2022-09-09T01:48:01.433Z</lastmod>
    <data>
        <display>
        <title>Vue版本Echarts中国地图三级钻取及Vue踩坑笔记</title>
        <pubTime>2019-02-17T16:00:00.000Z</pubTime>
        
        <tag>Echarts</tag>
         
        <tag>front-end</tag>
         
        <tag>Vue</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/11/27/echartsChinaMap/</loc>
    <lastmod>2022-09-09T01:45:06.834Z</lastmod>
    <data>
        <display>
        <title>Echarts中国地图三级钻取</title>
        <pubTime>2018-11-26T16:00:00.000Z</pubTime>
        
        <tag>Echarts</tag>
         
        <tag>front-end</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/06/12/hudiDeltaStreamer/</loc>
    <lastmod>2022-09-02T09:55:58.503Z</lastmod>
    <data>
        <display>
        <title>Hudi DeltaStreamer使用总结</title>
        <pubTime>2022-06-11T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/08/26/flinkSqlClientQueryHive/</loc>
    <lastmod>2022-08-27T08:16:32.454Z</lastmod>
    <data>
        <display>
        <title>Flink SQL 客户端查询Hive配置及问题解决</title>
        <pubTime>2022-08-25T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
        <tag>Flink</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/05/13/hudiSparkSQL/</loc>
    <lastmod>2022-08-16T05:56:20.703Z</lastmod>
    <data>
        <display>
        <title>Hudi Spark SQL总结</title>
        <pubTime>2022-05-12T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/08/15/hudiSparkSqlSourceCodeLearning-select/</loc>
    <lastmod>2022-08-15T08:18:57.950Z</lastmod>
    <data>
        <display>
        <title>Hudi Spark SQL源码学习总结-select（查询）</title>
        <pubTime>2022-08-14T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/08/12/hudiSparkSourceCodeLearning-dfLoad2/</loc>
    <lastmod>2022-08-12T03:04:59.193Z</lastmod>
    <data>
        <display>
        <title>Hudi Spark源码学习总结-spark.read.format("hudi").load（2）</title>
        <pubTime>2022-08-11T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/08/11/hudiSparkSourceCodeLearning-dfLoad/</loc>
    <lastmod>2022-08-12T01:29:50.015Z</lastmod>
    <data>
        <display>
        <title>Hudi Spark源码学习总结-spark.read.format("hudi").load</title>
        <pubTime>2022-08-10T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/08/03/hudiSparkSourceCodeLearning-dfSave/</loc>
    <lastmod>2022-08-10T01:55:19.560Z</lastmod>
    <data>
        <display>
        <title>Hudi Spark源码学习总结-df.write.format("hudi").save</title>
        <pubTime>2022-08-02T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/07/30/hudiSparkSqlSourceCodeLearning-ctas/</loc>
    <lastmod>2022-08-09T00:37:32.847Z</lastmod>
    <data>
        <display>
        <title>Hudi Spark SQL源码学习总结-CTAS</title>
        <pubTime>2022-07-29T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/03/sparkCacheAndPersist/</loc>
    <lastmod>2022-08-04T09:09:15.252Z</lastmod>
    <data>
        <display>
        <title>Spark 持久化（cache和persist的区别）</title>
        <pubTime>2018-06-02T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>持久化</tag>
         
        <tag>cache</tag>
         
        <tag>persist</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/05/12/hudiIntroduction/</loc>
    <lastmod>2022-08-04T09:09:00.042Z</lastmod>
    <data>
        <display>
        <title>Apache Hudi 入门学习总结</title>
        <pubTime>2022-05-11T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hive</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/23/oggOracle2Kafka/</loc>
    <lastmod>2022-08-04T09:07:22.313Z</lastmod>
    <data>
        <display>
        <title>利用ogg实现oracle到kafka的增量数据实时同步</title>
        <pubTime>2018-05-22T16:00:00.000Z</pubTime>
        
        <tag>Kafka</tag>
         
        <tag>ogg</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/25/ambariConf/</loc>
    <lastmod>2022-08-04T09:07:06.033Z</lastmod>
    <data>
        <display>
        <title>centos7 ambari2.6.1.5+hdp2.6.4.0 大数据集群安装部署</title>
        <pubTime>2018-04-24T16:00:00.000Z</pubTime>
        
        <tag>ambari</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/10/ambariExceptions/</loc>
    <lastmod>2022-08-04T09:06:54.924Z</lastmod>
    <data>
        <display>
        <title>ambari 异常总结及解决办法</title>
        <pubTime>2018-07-09T16:00:00.000Z</pubTime>
        
        <tag>ambari</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/12/27/anacondaInstall/</loc>
    <lastmod>2022-08-04T09:06:44.698Z</lastmod>
    <data>
        <display>
        <title>python anaconda 安装使用</title>
        <pubTime>2019-12-26T16:00:00.000Z</pubTime>
        
        <tag>python</tag>
         
        <tag>anaconda</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/07/06/sparkKyuubiPackConf/</loc>
    <lastmod>2022-08-04T03:05:59.147Z</lastmod>
    <data>
        <display>
        <title>Spark3.12+Kyuubi1.5.2+kyuubi-spark-authz源码编译打包+部署配置HA</title>
        <pubTime>2022-07-05T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Kyuubi</tag>
         
        <tag>Ranger</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/02/11/sparkThriftServerHA/</loc>
    <lastmod>2022-07-28T11:42:02.957Z</lastmod>
    <data>
        <display>
        <title>Spark Thrift Server HA 解决方案</title>
        <pubTime>2022-02-10T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/07/20/hudiSparkSqlSourceCodeLearning/</loc>
    <lastmod>2022-07-23T07:38:00.301Z</lastmod>
    <data>
        <display>
        <title>Hudi Spark SQL源码学习总结-Create Table</title>
        <pubTime>2022-07-19T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/06/29/hudiQueryTypes/</loc>
    <lastmod>2022-07-04T11:24:31.740Z</lastmod>
    <data>
        <display>
        <title>Hudi查询类型/视图总结</title>
        <pubTime>2022-06-28T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/06/27/hiveIncrQueryHudi/</loc>
    <lastmod>2022-06-28T09:44:23.493Z</lastmod>
    <data>
        <display>
        <title>Hive增量查询Hudi表</title>
        <pubTime>2022-06-26T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/06/22/hadoopSourceCodeCompilation/</loc>
    <lastmod>2022-06-28T08:45:36.527Z</lastmod>
    <data>
        <display>
        <title>Hadoop源码编译打包</title>
        <pubTime>2022-06-21T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>源码</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/12/02/submarinSparkRanger/</loc>
    <lastmod>2022-06-07T08:47:11.511Z</lastmod>
    <data>
        <display>
        <title>利用Submarin集成Spark-Ranger</title>
        <pubTime>2021-12-01T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Ranger</tag>
         
        <tag>Submarin</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/02/15/sparkSqlJdbc2Hudi/</loc>
    <lastmod>2022-06-07T08:47:11.454Z</lastmod>
    <data>
        <display>
        <title>SparkSQL JDBC 查询Oracle、MySQL 转化为Hudi表</title>
        <pubTime>2022-02-14T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hudi</tag>
         
        <tag>SparkSQL</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/12/23/prestoHudiException/</loc>
    <lastmod>2022-06-07T08:47:11.442Z</lastmod>
    <data>
        <display>
        <title>Presto查询Hudi异常解决</title>
        <pubTime>2021-12-22T16:00:00.000Z</pubTime>
        
        <tag>HUDI</tag>
         
        <tag>Presto</tag>
         
        <tag>异常</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/04/18/hudiClean/</loc>
    <lastmod>2022-05-20T05:47:01.382Z</lastmod>
    <data>
        <display>
        <title>Hudi Clean 清理文件实现分析</title>
        <pubTime>2022-04-17T16:00:00.000Z</pubTime>
        
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/07/10/hudiPreCombinedField/</loc>
    <lastmod>2022-05-17T11:44:01.852Z</lastmod>
    <data>
        <display>
        <title>HUDI preCombinedField 总结</title>
        <pubTime>2021-07-09T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>HUDI</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/04/19/hudiCleanPolicy/</loc>
    <lastmod>2022-05-16T00:41:19.793Z</lastmod>
    <data>
        <display>
        <title>Hudi Clean Policy 清理策略实现分析</title>
        <pubTime>2022-04-18T16:00:00.000Z</pubTime>
        
        <tag>Hudi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/05/10/javaSparkThriftServerWithKerberos/</loc>
    <lastmod>2022-05-12T00:38:17.298Z</lastmod>
    <data>
        <display>
        <title>Java 连接 Kerberos认证下的Spark Thrift Server/Hive Server总结</title>
        <pubTime>2021-05-09T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>hive</tag>
         
        <tag>java</tag>
         
        <tag>kerberos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2022/03/25/kyuubiConf/</loc>
    <lastmod>2022-03-25T09:48:52.111Z</lastmod>
    <data>
        <display>
        <title>Kyuubi 安装配置总结</title>
        <pubTime>2022-03-24T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hudi</tag>
         
        <tag>Kyuubi</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/05/29/oracleAndMysqlNull/</loc>
    <lastmod>2021-12-01T09:48:30.735Z</lastmod>
    <data>
        <display>
        <title>Oracle和MySQL如何判断是否为空或NULL</title>
        <pubTime>2019-05-28T16:00:00.000Z</pubTime>
        
        <tag>Oracle</tag>
         
        <tag>sql</tag>
         
        <tag>MySQL</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/11/30/hudiPreCombineField2/</loc>
    <lastmod>2021-12-01T06:48:14.530Z</lastmod>
    <data>
        <display>
        <title>HUDI preCombinedField 总结(二)-源码分析</title>
        <pubTime>2021-11-29T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>HUDI</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/05/19/localSparkHiveWithKerberos/</loc>
    <lastmod>2021-06-17T03:45:45.458Z</lastmod>
    <data>
        <display>
        <title>Spark 本地连接远程服务器上带有kerberos认证的Hive</title>
        <pubTime>2021-05-18T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>hive</tag>
         
        <tag>kerberos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/06/16/dfAddCols/</loc>
    <lastmod>2021-06-16T06:12:11.846Z</lastmod>
    <data>
        <display>
        <title>Spark DataFrame 添加列总结</title>
        <pubTime>2021-06-15T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/04/23/sparkSqlExecutionFlow/</loc>
    <lastmod>2021-06-04T01:58:19.976Z</lastmod>
    <data>
        <display>
        <title>Spark Sql 执行流程源码阅读笔记</title>
        <pubTime>2021-04-22T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/01/16/sparkHivePartitionOverwrite/</loc>
    <lastmod>2021-06-04T01:16:32.201Z</lastmod>
    <data>
        <display>
        <title>Spark 覆盖写Hive分区表,只覆盖部分对应分区</title>
        <pubTime>2020-01-15T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hive</tag>
         
        <tag>Partition</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/01/02/pycharmInstall/</loc>
    <lastmod>2021-06-04T01:07:58.920Z</lastmod>
    <data>
        <display>
        <title>windows 安装 pycharm 笔记</title>
        <pubTime>2020-01-01T16:00:00.000Z</pubTime>
        
        <tag>python</tag>
         
        <tag>pycharm</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/06/03/dbeaverConnectKerberosHive/</loc>
    <lastmod>2021-06-04T00:46:41.048Z</lastmod>
    <data>
        <display>
        <title>通过DBeaver本地访问远程Kerberos环境下的Hive</title>
        <pubTime>2021-06-02T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hive</tag>
         
        <tag>DBeaver</tag>
         
        <tag>Kerberos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/02/19/javaSparkThriftServer/</loc>
    <lastmod>2021-05-08T06:35:45.245Z</lastmod>
    <data>
        <display>
        <title>Java 连接 Spark Thrift Server/Hive Server总结</title>
        <pubTime>2021-02-18T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>hive</tag>
         
        <tag>java</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/04/29/SparkMysqlOverwriteTruncateTable/</loc>
    <lastmod>2021-04-29T11:49:08.715Z</lastmod>
    <data>
        <display>
        <title>Spark覆盖写入mysql表但不改变已有的表结构</title>
        <pubTime>2021-04-28T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>mysql</tag>
         
        <tag>源码</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/11/17/hadoopExcepetion2/</loc>
    <lastmod>2021-04-27T08:25:24.046Z</lastmod>
    <data>
        <display>
        <title>java.lang.UnsatisfiedLinkError:org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z</title>
        <pubTime>2020-11-16T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>ambari</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2021/03/19/SparkCompression/</loc>
    <lastmod>2021-03-19T09:51:39.066Z</lastmod>
    <data>
        <display>
        <title>Spark Sql 创建 Hive表的压缩格式</title>
        <pubTime>2021-03-18T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/11/19/sbtSupportJava/</loc>
    <lastmod>2021-02-26T07:22:43.398Z</lastmod>
    <data>
        <display>
        <title>sbt 支持打包Java程序</title>
        <pubTime>2019-11-18T16:00:00.000Z</pubTime>
        
        <tag>sbt</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/12/26/sparkCoarseGrainedExecutorBackendStartedProcess/</loc>
    <lastmod>2020-12-28T09:47:35.663Z</lastmod>
    <data>
        <display>
        <title>Spark CoarseGrainedExecutorBackend 启动流程</title>
        <pubTime>2020-12-25T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/12/23/sparkRPC/</loc>
    <lastmod>2020-12-24T10:00:04.447Z</lastmod>
    <data>
        <display>
        <title>Spark RPC 学习笔记</title>
        <pubTime>2020-12-22T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>源码</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/10/HadoopException/</loc>
    <lastmod>2020-11-17T08:43:56.697Z</lastmod>
    <data>
        <display>
        <title>HDFS DataNode启动异常:/opt/jdk1.8.0_151/bin/java:权限不够</title>
        <pubTime>2018-07-09T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>ambari</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/10/26/vmwareClone/</loc>
    <lastmod>2020-10-26T09:31:27.601Z</lastmod>
    <data>
        <display>
        <title>vmware centos7 克隆</title>
        <pubTime>2020-10-25T16:00:00.000Z</pubTime>
        
        <tag>centos7</tag>
         
        <tag>vmware</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/10/09/spark3StreamingException/</loc>
    <lastmod>2020-10-09T12:05:35.628Z</lastmod>
    <data>
        <display>
        <title>Spark 3.0.1 Structured Streaming 提交程序异常解决</title>
        <pubTime>2020-10-08T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>异常</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/08/14/hbaseConf/</loc>
    <lastmod>2020-09-27T02:14:19.600Z</lastmod>
    <data>
        <display>
        <title>centos7 hbase1.4.13+hadoop2.7.1+单机环境搭建</title>
        <pubTime>2020-08-13T16:00:00.000Z</pubTime>
        
        <tag>centos7</tag>
         
        <tag>hbase</tag>
         
        <tag>hadoop</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/08/19/javaHbase/</loc>
    <lastmod>2020-08-19T08:54:55.712Z</lastmod>
    <data>
        <display>
        <title>Java API 连接 Hbase示例</title>
        <pubTime>2020-08-18T16:00:00.000Z</pubTime>
        
        <tag>hbase</tag>
         
        <tag>java</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/06/06/linuxCrontab/</loc>
    <lastmod>2020-03-18T06:41:10.748Z</lastmod>
    <data>
        <display>
        <title>Linux 定时任务命令crontab学习总结</title>
        <pubTime>2019-06-05T16:00:00.000Z</pubTime>
        
        <tag>Linux</tag>
         
        <tag>crontab</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/03/14/sparkDfLengthIs0/</loc>
    <lastmod>2020-03-14T07:27:27.459Z</lastmod>
    <data>
        <display>
        <title>Spark 判断DataFrame 长度为0</title>
        <pubTime>2020-03-13T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/01/21/sparkDfIsin/</loc>
    <lastmod>2020-01-21T07:39:53.300Z</lastmod>
    <data>
        <display>
        <title>Spark DataFrame isin方法使用</title>
        <pubTime>2020-01-20T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2020/01/03/pythonMysql/</loc>
    <lastmod>2020-01-03T06:51:42.546Z</lastmod>
    <data>
        <display>
        <title>Python 连接 MYSQL</title>
        <pubTime>2020-01-02T16:00:00.000Z</pubTime>
        
        <tag>Python</tag>
         
        <tag>MYSQL</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/12/30/pythonExcel/</loc>
    <lastmod>2020-01-03T01:14:47.610Z</lastmod>
    <data>
        <display>
        <title>Python 处理Excel总结(1)</title>
        <pubTime>2019-12-29T16:00:00.000Z</pubTime>
        
        <tag>python</tag>
         
        <tag>excel</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/12/24/2019-12-24/</loc>
    <lastmod>2019-12-24T11:04:07.349Z</lastmod>
    <data>
        <display>
        <title>英语学习</title>
        <pubTime>2019-12-23T16:00:00.000Z</pubTime>
        
        <tag>english</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/05/31/2019-05-31/</loc>
    <lastmod>2019-12-23T11:43:38.884Z</lastmod>
    <data>
        <display>
        <title>英语学习</title>
        <pubTime>2019-05-30T16:00:00.000Z</pubTime>
        
        <tag>english</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/12/23/2019-12-23/</loc>
    <lastmod>2019-12-23T11:43:32.060Z</lastmod>
    <data>
        <display>
        <title>英语学习</title>
        <pubTime>2019-12-22T16:00:00.000Z</pubTime>
        
        <tag>english</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/12/02/SQLRegExp/</loc>
    <lastmod>2019-12-02T11:51:18.624Z</lastmod>
    <data>
        <display>
        <title>Oracle、Spark、Hive SQL 正则总结</title>
        <pubTime>2019-12-01T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>SQL</tag>
         
        <tag>Oracle</tag>
         
        <tag>Hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/07/29/sqlUnion/</loc>
    <lastmod>2019-10-25T11:23:27.821Z</lastmod>
    <data>
        <display>
        <title>SQL UNION 和 UNION ALL</title>
        <pubTime>2019-07-28T16:00:00.000Z</pubTime>
        
        <tag>SQL</tag>
         
        <tag>UNION</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/26/sparkSqlOptimize/</loc>
    <lastmod>2019-08-13T12:20:53.564Z</lastmod>
    <data>
        <display>
        <title>Spark SQL 优化笔记</title>
        <pubTime>2018-12-25T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>SQL</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/07/16/ideaMavenScalaJava/</loc>
    <lastmod>2019-07-18T13:18:58.550Z</lastmod>
    <data>
        <display>
        <title>IDEA 新建Maven项目同时支持Java和Scala两种语言</title>
        <pubTime>2019-07-15T16:00:00.000Z</pubTime>
        
        <tag>Scala</tag>
         
        <tag>IDEA</tag>
         
        <tag>Maven</tag>
         
        <tag>Java</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/07/03/elkbConf/</loc>
    <lastmod>2019-07-04T01:14:54.342Z</lastmod>
    <data>
        <display>
        <title>Centos7 ELKB 7.2.0版本单机部署</title>
        <pubTime>2019-07-02T16:00:00.000Z</pubTime>
        
        <tag>centos7</tag>
         
        <tag>ELKB</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/06/10/kafkaLearing/</loc>
    <lastmod>2019-06-16T05:53:00.075Z</lastmod>
    <data>
        <display>
        <title>Kafka学习笔记（1）</title>
        <pubTime>2019-06-09T16:00:00.000Z</pubTime>
        
        <tag>Kafka</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/06/05/sealedClasses/</loc>
    <lastmod>2019-06-05T06:57:18.383Z</lastmod>
    <data>
        <display>
        <title>Sealed classes</title>
        <pubTime>2019-06-04T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/06/04/vueDeployGithubPages/</loc>
    <lastmod>2019-06-05T06:56:51.872Z</lastmod>
    <data>
        <display>
        <title>将Vue项目部署到Github Page上</title>
        <pubTime>2019-06-03T16:00:00.000Z</pubTime>
        
        <tag>vue</tag>
         
        <tag>git</tag>
         
        <tag>git-page</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/06/03/use-setWeightCol-dealing-with-unbalanced-datasets-in-spark-ml/</loc>
    <lastmod>2019-06-04T06:40:55.159Z</lastmod>
    <data>
        <display>
        <title>Spark ML LR 用 setWeightCol 解决数据不平衡</title>
        <pubTime>2019-06-02T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>算法</tag>
         
        <tag>ml</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/05/30/sparkCsvException/</loc>
    <lastmod>2019-05-30T14:33:34.681Z</lastmod>
    <data>
        <display>
        <title>Spark读取CSV异常 java.lang.ArrayIndexOutOfBoundsException:62</title>
        <pubTime>2019-05-29T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>异常</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/01/scalaDate/</loc>
    <lastmod>2019-05-30T11:14:22.189Z</lastmod>
    <data>
        <display>
        <title>Scala日期操作</title>
        <pubTime>2018-05-31T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
        <tag>日期</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/05/28/mysqlAndOracleSubString/</loc>
    <lastmod>2019-05-28T10:03:06.891Z</lastmod>
    <data>
        <display>
        <title>MySQL和Oracle字符串截取函数用法总结（比较）</title>
        <pubTime>2019-05-27T16:00:00.000Z</pubTime>
        
        <tag>Oracle</tag>
         
        <tag>sql</tag>
         
        <tag>MySQL</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/05/27/LR1/</loc>
    <lastmod>2019-05-28T02:43:07.543Z</lastmod>
    <data>
        <display>
        <title>Logistic Regression 学习总结</title>
        <pubTime>2019-05-26T16:00:00.000Z</pubTime>
        
        <tag>算法</tag>
         
        <tag>Logistic Regression</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/13/dbeaverConnectHive/</loc>
    <lastmod>2019-05-27T01:02:27.541Z</lastmod>
    <data>
        <display>
        <title>通过数据库客户端界面工具DBeaver连接Hive</title>
        <pubTime>2018-07-12T16:00:00.000Z</pubTime>
        
        <tag>界面工具</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/10/23/tomcatConf/</loc>
    <lastmod>2019-05-23T01:08:22.274Z</lastmod>
    <data>
        <display>
        <title>Centos7 Tomcat9 安装笔记</title>
        <pubTime>2018-10-22T16:00:00.000Z</pubTime>
        
        <tag>tomcat</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/02/hivePartitionTable/</loc>
    <lastmod>2019-05-23T01:01:41.722Z</lastmod>
    <data>
        <display>
        <title>Hive分区表学习总结</title>
        <pubTime>2018-12-01T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
        <tag>Partition</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/01/09/sparkExceptions/</loc>
    <lastmod>2019-05-22T03:53:58.569Z</lastmod>
    <data>
        <display>
        <title>Spark 异常总结及解决办法</title>
        <pubTime>2019-01-08T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/07/hiveBucketTable/</loc>
    <lastmod>2019-05-09T02:31:43.693Z</lastmod>
    <data>
        <display>
        <title>Hive分桶表学习总结</title>
        <pubTime>2018-12-06T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
        <tag>bucket</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/15/winSparkConf/</loc>
    <lastmod>2019-05-09T01:50:10.108Z</lastmod>
    <data>
        <display>
        <title>win10 spark+scala+eclipse+sbt 安装配置</title>
        <pubTime>2018-03-14T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/11/19/vueCliCreateProject/</loc>
    <lastmod>2019-05-09T01:50:05.164Z</lastmod>
    <data>
        <display>
        <title>通过Vue CLI 快速创建Vue项目并部署到tomcat</title>
        <pubTime>2018-11-18T16:00:00.000Z</pubTime>
        
        <tag>Vue</tag>
         
        <tag>Vue CLI</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/16/vmwareSetFixIP/</loc>
    <lastmod>2019-05-09T01:49:59.658Z</lastmod>
    <data>
        <display>
        <title>vmware centos7 设置固定ip</title>
        <pubTime>2018-01-15T16:00:00.000Z</pubTime>
        
        <tag>vmware</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/14/updateStateBykeyWordCount/</loc>
    <lastmod>2019-05-09T01:49:54.260Z</lastmod>
    <data>
        <display>
        <title>SparkStreaming+Kafka 实现基于缓存的实时wordcount程序</title>
        <pubTime>2018-06-13T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>SparkStreaming</tag>
         
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/sshConf/</loc>
    <lastmod>2019-05-09T01:49:46.376Z</lastmod>
    <data>
        <display>
        <title>linux ssh 免密登录</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>linux</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/02/sparkUDF/</loc>
    <lastmod>2019-05-09T01:49:41.408Z</lastmod>
    <data>
        <display>
        <title>Spark UDF使用详解及代码示例</title>
        <pubTime>2018-08-01T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
        <tag>UDF</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/11/16/sparkSubmitLogLevel/</loc>
    <lastmod>2019-05-09T01:49:35.458Z</lastmod>
    <data>
        <display>
        <title>Spark 通过 spark-submit 设置日志级别</title>
        <pubTime>2018-11-15T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/06/sparkSubmitException1/</loc>
    <lastmod>2019-05-09T01:49:29.328Z</lastmod>
    <data>
        <display>
        <title>spark-submit报错:Application application_1529650293575_0148 finished with failed status</title>
        <pubTime>2018-07-05T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/20/sparkStreamingOffsetOnlyOnce/</loc>
    <lastmod>2019-05-09T01:49:22.364Z</lastmod>
    <data>
        <display>
        <title>Spark Streaming+Kafka提交offset实现有且仅有一次(exactly-once)</title>
        <pubTime>2018-06-19T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Kafka</tag>
         
        <tag>Spark Streaming</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/27/sparkOracle2Hive/</loc>
    <lastmod>2019-05-09T01:49:15.549Z</lastmod>
    <data>
        <display>
        <title>利用Spark实现Oracle到Hive的历史数据同步</title>
        <pubTime>2018-08-26T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Oracle</tag>
         
        <tag>Hive</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/16/sparkOnYarnConf/</loc>
    <lastmod>2019-05-09T01:49:12.990Z</lastmod>
    <data>
        <display>
        <title>spark on yarn 配置及异常解决</title>
        <pubTime>2018-04-15T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>yarn</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/11/sparkNewUV/</loc>
    <lastmod>2019-05-09T01:49:10.054Z</lastmod>
    <data>
        <display>
        <title>Spark 统计每天新增用户数</title>
        <pubTime>2018-04-10T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Scala</tag>
         
        <tag>面试题</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/21/sparkMysql/</loc>
    <lastmod>2019-05-09T01:49:05.367Z</lastmod>
    <data>
        <display>
        <title>Spark Sql 连接mysql</title>
        <pubTime>2018-03-20T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/09/02/sparkMapPartitions/</loc>
    <lastmod>2019-05-09T01:48:56.699Z</lastmod>
    <data>
        <display>
        <title>Spark性能优化：基于分区进行操作</title>
        <pubTime>2018-09-01T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Partitions</tag>
         
        <tag>性能优化</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/17/sparkKafka/</loc>
    <lastmod>2019-05-09T01:48:53.313Z</lastmod>
    <data>
        <display>
        <title>Spark Streaming连接Kafka入门教程</title>
        <pubTime>2018-05-16T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Kafka</tag>
         
        <tag>Spark Streaming</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/25/sparkHive/</loc>
    <lastmod>2019-05-09T01:48:48.035Z</lastmod>
    <data>
        <display>
        <title>Spark连接Hive（spark-shell和Eclipse两种方式）</title>
        <pubTime>2018-03-24T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/30/sparkGZ/</loc>
    <lastmod>2019-05-09T01:48:42.653Z</lastmod>
    <data>
        <display>
        <title>Spark读取压缩文件</title>
        <pubTime>2018-05-29T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>压缩文件</tag>
         
        <tag>编码问题</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/28/sparkGetPartitionId/</loc>
    <lastmod>2019-05-09T01:48:38.327Z</lastmod>
    <data>
        <display>
        <title>Spark获取当前分区的partitionId</title>
        <pubTime>2018-06-27T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Partition</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/14/sparkEmptyDataFrame/</loc>
    <lastmod>2019-05-09T01:48:27.795Z</lastmod>
    <data>
        <display>
        <title>Spark创建空的DataFrame</title>
        <pubTime>2018-08-13T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/20/sparkDfAddComments/</loc>
    <lastmod>2019-05-09T01:48:21.743Z</lastmod>
    <data>
        <display>
        <title>Spark通过修改DataFrame的schema给表字段添加注释</title>
        <pubTime>2018-08-19T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/08/13/sparkDefaultPartitionNums/</loc>
    <lastmod>2019-05-09T01:48:09.927Z</lastmod>
    <data>
        <display>
        <title>Spark 创建RDD、DataFrame各种情况的默认分区数</title>
        <pubTime>2018-08-12T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
        <tag>Partition</tag>
         
        <tag>Rdd</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/09/sparkArchitecturePrinciples/</loc>
    <lastmod>2019-05-09T01:47:54.484Z</lastmod>
    <data>
        <display>
        <title>Spark架构原理</title>
        <pubTime>2018-06-08T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>原理</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/11/rdd2df/</loc>
    <lastmod>2019-05-09T01:47:42.192Z</lastmod>
    <data>
        <display>
        <title>旧版Spark（1.6版本） 将RDD动态转为DataFrame</title>
        <pubTime>2018-05-10T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
        <tag>Rdd</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/05/oracleConf/</loc>
    <lastmod>2019-05-09T01:47:36.874Z</lastmod>
    <data>
        <display>
        <title>Centos7 安装oracle11</title>
        <pubTime>2018-05-04T16:00:00.000Z</pubTime>
        
        <tag>centos7</tag>
         
        <tag>oracle</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/04/24/nginxInstallConf/</loc>
    <lastmod>2019-05-09T01:47:24.308Z</lastmod>
    <data>
        <display>
        <title>Nginx 安装配置</title>
        <pubTime>2019-04-23T16:00:00.000Z</pubTime>
        
        <tag>Nginx</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/29/linux-oh-my-zsh/</loc>
    <lastmod>2019-05-09T01:47:09.193Z</lastmod>
    <data>
        <display>
        <title>Linux 安装 oh-my-zsh</title>
        <pubTime>2018-12-28T16:00:00.000Z</pubTime>
        
        <tag>Linux</tag>
         
        <tag>zsh</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/25/KafkaUV/</loc>
    <lastmod>2019-05-09T01:47:04.305Z</lastmod>
    <data>
        <display>
        <title>SparkStreaming+Kafka 实现统计基于缓存的实时uv</title>
        <pubTime>2018-06-24T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>SparkStreaming</tag>
         
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/21/kafkaConf/</loc>
    <lastmod>2019-05-09T01:46:57.094Z</lastmod>
    <data>
        <display>
        <title>Kafka安装启动入门教程</title>
        <pubTime>2018-05-20T16:00:00.000Z</pubTime>
        
        <tag>Kafka</tag>
         
        <tag>centos7</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/20/hiveQueryException/</loc>
    <lastmod>2019-05-09T01:46:49.683Z</lastmod>
    <data>
        <display>
        <title>hive查询报错:java.io.IOException:org.apache.parquet.io.ParquetDecodingException</title>
        <pubTime>2018-05-19T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>hive</tag>
         
        <tag>异常解决</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/03/hiveInternalAndExternalTables/</loc>
    <lastmod>2019-05-09T01:46:42.226Z</lastmod>
    <data>
        <display>
        <title>Hive内部表和外部表</title>
        <pubTime>2018-12-02T16:00:00.000Z</pubTime>
        
        <tag>Hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/24/hiveConf/</loc>
    <lastmod>2019-05-09T01:46:37.956Z</lastmod>
    <data>
        <display>
        <title>centos7 hive 单机模式安装配置</title>
        <pubTime>2018-03-23T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
        <tag>hive</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/23/hadoopConf/</loc>
    <lastmod>2019-05-09T01:46:22.736Z</lastmod>
    <data>
        <display>
        <title>centos7 hadoop 单机模式安装配置</title>
        <pubTime>2018-03-22T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/hadoopClusterConf/</loc>
    <lastmod>2019-05-09T01:46:17.463Z</lastmod>
    <data>
        <display>
        <title>centos7 hadoop 集群安装配置</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>Hadoop</tag>
         
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/11/20/getAllHDFSFileNames/</loc>
    <lastmod>2019-05-09T01:46:12.492Z</lastmod>
    <data>
        <display>
        <title>打印（获取）HDFS路径下所有的文件名（包括子目录下的）</title>
        <pubTime>2018-11-19T16:00:00.000Z</pubTime>
        
        <tag>Scala</tag>
         
        <tag>HDFS</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2019/03/28/vueAutoIpAndOpenBrowser/</loc>
    <lastmod>2019-03-29T01:52:27.425Z</lastmod>
    <data>
        <display>
        <title>Vue 自动获取本地ip，并打开浏览器</title>
        <pubTime>2019-03-27T16:00:00.000Z</pubTime>
        
        <tag>Vue</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
  <url>
    <loc>https://dongkelun.com/2019/01/07/sparkCheckPoint/</loc>
    <lastmod>2019-01-10T05:38:16.455Z</lastmod>
    <data>
        <display>
        <title>Spark Checkpoint 使用及源码浅析</title>
        <pubTime>2019-01-06T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>持久化</tag>
         
        <tag>cache</tag>
         
        <tag>persist</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/14/scalaLearningNotes/</loc>
    <lastmod>2019-01-07T03:31:09.161Z</lastmod>
    <data>
        <display>
        <title>Scala学习笔记</title>
        <pubTime>2018-12-13T16:00:00.000Z</pubTime>
        
        <tag>Scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/17/sparkMlFeatureProcessing1/</loc>
    <lastmod>2018-12-07T15:35:20.561Z</lastmod>
    <data>
        <display>
        <title>spark ML之特征处理（1）</title>
        <pubTime>2018-05-16T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>ml</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/06/sparkSubmitException/</loc>
    <lastmod>2018-12-06T14:46:46.148Z</lastmod>
    <data>
        <display>
        <title>spark-submit报错:Exception in thread "main" java.sql.SQLException:No suitable driver</title>
        <pubTime>2018-05-05T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
  <url>
    <loc>https://dongkelun.com/2018/04/27/dfChangeAllColDatatypes/</loc>
    <lastmod>2018-12-05T03:20:42.111Z</lastmod>
    <data>
        <display>
        <title>Spark 将DataFrame所有的列类型改为double</title>
        <pubTime>2018-04-26T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/12/04/sparkHivePatition/</loc>
    <lastmod>2018-12-04T13:51:30.896Z</lastmod>
    <data>
        <display>
        <title>Spark操作Hive分区表</title>
        <pubTime>2018-12-03T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Hive</tag>
         
        <tag>Partition</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/09/sparkMlLinearRegressionUsing/</loc>
    <lastmod>2018-12-02T14:20:36.911Z</lastmod>
    <data>
        <display>
        <title>spark ML算法之线性回归使用</title>
        <pubTime>2018-04-08T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>算法</tag>
         
        <tag>ml</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/19/sparkSubmitKafka/</loc>
    <lastmod>2018-11-16T02:30:08.086Z</lastmod>
    <data>
        <display>
        <title>spark-submit提交Spark Streaming+Kafka程序</title>
        <pubTime>2018-06-18T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>Kafka</tag>
         
        <tag>Spark Streaming</tag>
         
        <tag>spark-submit</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/05/27/sparkDelFirstNLines/</loc>
    <lastmod>2018-11-16T01:54:22.727Z</lastmod>
    <data>
        <display>
        <title>如何解决Spark开发中遇到需要去掉文件前几行数据的问题</title>
        <pubTime>2018-05-26T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>rdd</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/23/sparkBasicConcept/</loc>
    <lastmod>2018-11-16T01:47:04.768Z</lastmod>
    <data>
        <display>
        <title>Spark基本概念（便于自己随时查阅--摘自Spark快速大数据分析）</title>
        <pubTime>2018-01-22T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
    
    
  <url>
    <loc>https://dongkelun.com/2018/03/29/scalaUnderscoreUseGuide/</loc>
    <lastmod>2018-07-05T09:02:47.900Z</lastmod>
    <data>
        <display>
        <title>scala 下划线使用指南</title>
        <pubTime>2018-03-28T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
        <tag>转载</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/05/centosInitialConf/</loc>
    <lastmod>2018-07-05T09:02:38.485Z</lastmod>
    <data>
        <display>
        <title>CentOS 初始环境配置</title>
        <pubTime>2018-04-04T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/22/ibatisTransaction/</loc>
    <lastmod>2018-07-05T09:02:31.562Z</lastmod>
    <data>
        <display>
        <title>ibatis 事务 java</title>
        <pubTime>2018-01-21T16:00:00.000Z</pubTime>
        
        <tag>ibatis</tag>
         
        <tag>java</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/03/22/mysqlTimeZoneErr/</loc>
    <lastmod>2018-07-05T09:02:26.200Z</lastmod>
    <data>
        <display>
        <title>连接mysql报错：Exception in thread "main" java.sql.SQLException:The server time zone value 'EDT' is unrecognized or represents more than one time zone</title>
        <pubTime>2018-03-21T16:00:00.000Z</pubTime>
        
        <tag>mysql</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/17/networkIsUnreachable/</loc>
    <lastmod>2018-07-05T09:02:19.842Z</lastmod>
    <data>
        <display>
        <title>network is unreachable centos无法连接外网（或unknown host baidu.com）</title>
        <pubTime>2018-01-16T16:00:00.000Z</pubTime>
        
        <tag>centos</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/01/09/redisClusterDeployment/</loc>
    <lastmod>2018-07-05T09:02:11.145Z</lastmod>
    <data>
        <display>
        <title>Redis Cluster 安装配置</title>
        <pubTime>2018-01-08T16:00:00.000Z</pubTime>
        
        <tag>redis</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/04/01/scalaMapAdd/</loc>
    <lastmod>2018-07-05T09:02:05.520Z</lastmod>
    <data>
        <display>
        <title>scala 两个map合并，key相同时value相加</title>
        <pubTime>2018-03-31T16:00:00.000Z</pubTime>
        
        <tag>scala</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/06/21/modifyKafkaOffsetTime/</loc>
    <lastmod>2018-07-05T08:58:47.677Z</lastmod>
    <data>
        <display>
        <title>通过offsets.retention.minutes设置kafka offset的过期时间</title>
        <pubTime>2018-06-20T16:00:00.000Z</pubTime>
        
        <tag>Kafka</tag>
         
         
           
        </display>
    </data>
    </url>

    
  <url>
    <loc>https://dongkelun.com/2018/07/04/sparkDfSortDesc/</loc>
    <lastmod>2018-07-05T08:57:30.983Z</lastmod>
    <data>
        <display>
        <title>Spark DataFrame按某列降序排序</title>
        <pubTime>2018-07-03T16:00:00.000Z</pubTime>
        
        <tag>Spark</tag>
         
        <tag>DataFrame</tag>
         
         
           
        </display>
    </data>
    </url>

    
    
    
</urlset>