[{"title":"Spark创建空的DataFrame","date":"2018-08-13T16:00:00.000Z","path":"2018/08/14/sparkEmptyDataFrame/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"}]},{"title":"Spark 创建RDD、DataFrame各种情况的默认分区数","date":"2018-08-12T16:00:00.000Z","path":"2018/08/13/sparkDefaultPartitionNums/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"},{"name":"Rdd","slug":"Rdd","permalink":"https://dongkelun.com/tags/Rdd/"},{"name":"Partition","slug":"Partition","permalink":"https://dongkelun.com/tags/Partition/"}]},{"title":"Spark UDF使用详解及代码示例","date":"2018-08-01T16:00:00.000Z","path":"2018/08/02/sparkUDF/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"},{"name":"UDF","slug":"UDF","permalink":"https://dongkelun.com/tags/UDF/"}]},{"title":"通过数据库客户端界面工具DBeaver连接Hive","date":"2018-07-12T16:00:00.000Z","path":"2018/07/13/dbeaverConnectHive/","categories":[],"tags":[{"name":"界面工具","slug":"界面工具","permalink":"https://dongkelun.com/tags/界面工具/"},{"name":"hive","slug":"hive","permalink":"https://dongkelun.com/tags/hive/"}]},{"title":"HDFS DataNode启动异常:/opt/jdk1.8.0_151/bin/java:权限不够","date":"2018-07-09T16:00:00.000Z","path":"2018/07/10/HadoopException/","categories":[],"tags":[{"name":"ambari","slug":"ambari","permalink":"https://dongkelun.com/tags/ambari/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://dongkelun.com/tags/Hadoop/"}]},{"title":"ambari 异常总结及解决办法","date":"2018-07-09T16:00:00.000Z","path":"2018/07/10/ambariExceptions/","categories":[],"tags":[{"name":"centos7","slug":"centos7","permalink":"https://dongkelun.com/tags/centos7/"},{"name":"ambari","slug":"ambari","permalink":"https://dongkelun.com/tags/ambari/"}]},{"title":"spark-submit报错:Application application_1529650293575_0148 finished with failed status","date":"2018-07-05T16:00:00.000Z","path":"2018/07/06/sparkSubmitException1/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"spark-submit","slug":"spark-submit","permalink":"https://dongkelun.com/tags/spark-submit/"}]},{"title":"Spark DataFrame按某列降序排序","date":"2018-07-03T16:00:00.000Z","path":"2018/07/04/sparkDfSortDesc/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"}]},{"title":"Spark获取当前分区的partitionId","date":"2018-06-27T16:00:00.000Z","path":"2018/06/28/sparkGetPartitionId/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Partition","slug":"Partition","permalink":"https://dongkelun.com/tags/Partition/"}]},{"title":"SparkStreaming+Kafka 实现统计基于缓存的实时uv","date":"2018-06-24T16:00:00.000Z","path":"2018/06/25/KafkaUV/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"SparkStreaming","slug":"SparkStreaming","permalink":"https://dongkelun.com/tags/SparkStreaming/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"}]},{"title":"通过offsets.retention.minutes设置kafka offset的过期时间","date":"2018-06-20T16:00:00.000Z","path":"2018/06/21/modifyKafkaOffsetTime/","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"}]},{"title":"Spark Streamming+Kafka提交offset实现有且仅有一次","date":"2018-06-19T16:00:00.000Z","path":"2018/06/20/sparkStreamingOffsetOnlyOnce/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"},{"name":"Spark Streamming","slug":"Spark-Streamming","permalink":"https://dongkelun.com/tags/Spark-Streamming/"}]},{"title":"spark-submit提交Spark Streamming+Kafka程序","date":"2018-06-18T16:00:00.000Z","path":"2018/06/19/sparkSubmitKafka/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"},{"name":"Spark Streamming","slug":"Spark-Streamming","permalink":"https://dongkelun.com/tags/Spark-Streamming/"},{"name":"spark-submit","slug":"spark-submit","permalink":"https://dongkelun.com/tags/spark-submit/"}]},{"title":"SparkStreaming+Kafka 实现基于缓存的实时wordcount程序","date":"2018-06-13T16:00:00.000Z","path":"2018/06/14/updateStateBykeyWordCount/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"SparkStreaming","slug":"SparkStreaming","permalink":"https://dongkelun.com/tags/SparkStreaming/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"}]},{"title":"Spark架构原理","date":"2018-06-08T16:00:00.000Z","path":"2018/06/09/sparkArchitecturePrinciples/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"原理","slug":"原理","permalink":"https://dongkelun.com/tags/原理/"}]},{"title":"Spark 持久化（cache和persist的区别）","date":"2018-06-02T16:00:00.000Z","path":"2018/06/03/sparkCacheAndPersist/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"持久化","slug":"持久化","permalink":"https://dongkelun.com/tags/持久化/"},{"name":"cache","slug":"cache","permalink":"https://dongkelun.com/tags/cache/"},{"name":"persist","slug":"persist","permalink":"https://dongkelun.com/tags/persist/"}]},{"title":"Scala日期操作","date":"2018-05-31T16:00:00.000Z","path":"2018/06/01/scalaDate/","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"},{"name":"日期","slug":"日期","permalink":"https://dongkelun.com/tags/日期/"}]},{"title":"Spark读取压缩文件","date":"2018-05-29T16:00:00.000Z","path":"2018/05/30/sparkGZ/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"压缩文件","slug":"压缩文件","permalink":"https://dongkelun.com/tags/压缩文件/"},{"name":"编码问题","slug":"编码问题","permalink":"https://dongkelun.com/tags/编码问题/"}]},{"title":"如何解决spark开发中遇到需要去掉文件前几行数据的问题","date":"2018-05-26T16:00:00.000Z","path":"2018/05/27/sparkDelFirstNLines/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"rdd","slug":"rdd","permalink":"https://dongkelun.com/tags/rdd/"}]},{"title":"利用ogg实现oracle到kafka的增量数据实时同步","date":"2018-05-22T16:00:00.000Z","path":"2018/05/23/oggOracle2Kafka/","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://dongkelun.com/tags/kafka/"},{"name":"ogg","slug":"ogg","permalink":"https://dongkelun.com/tags/ogg/"}]},{"title":"Kafka安装启动入门教程","date":"2018-05-20T16:00:00.000Z","path":"2018/05/21/kafkaConf/","categories":[],"tags":[{"name":"centos7","slug":"centos7","permalink":"https://dongkelun.com/tags/centos7/"},{"name":"kafka","slug":"kafka","permalink":"https://dongkelun.com/tags/kafka/"}]},{"title":"hive查询报错:java.io.IOException:org.apache.parquet.io.ParquetDecodingException","date":"2018-05-19T16:00:00.000Z","path":"2018/05/20/hiveQueryException/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"hive","slug":"hive","permalink":"https://dongkelun.com/tags/hive/"},{"name":"异常解决","slug":"异常解决","permalink":"https://dongkelun.com/tags/异常解决/"}]},{"title":"Spark Streaming连接Kafka入门教程","date":"2018-05-16T16:00:00.000Z","path":"2018/05/17/sparkKafka/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"kafka","slug":"kafka","permalink":"https://dongkelun.com/tags/kafka/"},{"name":"spark streaming","slug":"spark-streaming","permalink":"https://dongkelun.com/tags/spark-streaming/"}]},{"title":"spark ML之特征处理（1）","date":"2018-05-16T16:00:00.000Z","path":"2018/05/17/sparkMlFeatureProcessing1/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"ml","slug":"ml","permalink":"https://dongkelun.com/tags/ml/"}]},{"title":"旧版spark（1.6版本） 将rdd动态转为dataframe","date":"2018-05-10T16:00:00.000Z","path":"2018/05/11/rdd2df/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"},{"name":"Rdd","slug":"Rdd","permalink":"https://dongkelun.com/tags/Rdd/"}]},{"title":"spark-submit报错:Exception in thread \"main\" java.sql.SQLException:No suitable driver","date":"2018-05-05T16:00:00.000Z","path":"2018/05/06/sparkSubmitException/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"spark-submit","slug":"spark-submit","permalink":"https://dongkelun.com/tags/spark-submit/"}]},{"title":"centos7 安装oracle11","date":"2018-05-04T16:00:00.000Z","path":"2018/05/05/oracleConf/","categories":[],"tags":[{"name":"centos7","slug":"centos7","permalink":"https://dongkelun.com/tags/centos7/"},{"name":"oracle","slug":"oracle","permalink":"https://dongkelun.com/tags/oracle/"}]},{"title":"spark 将DataFrame所有的列类型改为double","date":"2018-04-26T16:00:00.000Z","path":"2018/04/27/dfChangeAllColDatatypes/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"}]},{"title":"centos7 ambari2.6.1.5+hdp2.6.4.0 大数据集群安装部署","date":"2018-04-24T16:00:00.000Z","path":"2018/04/25/ambariConf/","categories":[],"tags":[{"name":"centos7","slug":"centos7","permalink":"https://dongkelun.com/tags/centos7/"},{"name":"ambari","slug":"ambari","permalink":"https://dongkelun.com/tags/ambari/"}]},{"title":"spark on yarn 配置及异常解决","date":"2018-04-15T16:00:00.000Z","path":"2018/04/16/sparkOnYarnConf/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"yarn","slug":"yarn","permalink":"https://dongkelun.com/tags/yarn/"}]},{"title":"spark 统计每天新增用户数","date":"2018-04-10T16:00:00.000Z","path":"2018/04/11/sparkNewUV/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"},{"name":"面试题","slug":"面试题","permalink":"https://dongkelun.com/tags/面试题/"}]},{"title":"spark ML算法之线性回归使用","date":"2018-04-08T16:00:00.000Z","path":"2018/04/09/sparkMlLinearRegressionUsing/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"ml","slug":"ml","permalink":"https://dongkelun.com/tags/ml/"},{"name":"算法","slug":"算法","permalink":"https://dongkelun.com/tags/算法/"}]},{"title":"linux ssh 免密登录","date":"2018-04-04T16:00:00.000Z","path":"2018/04/05/sshConf/","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://dongkelun.com/tags/linux/"}]},{"title":"centos7 hadoop 集群安装配置","date":"2018-04-04T16:00:00.000Z","path":"2018/04/05/hadoopClusterConf/","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"},{"name":"hadoop","slug":"hadoop","permalink":"https://dongkelun.com/tags/hadoop/"}]},{"title":"CentOS 初始环境配置","date":"2018-04-04T16:00:00.000Z","path":"2018/04/05/centosInitialConf/","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"}]},{"title":"scala 两个map合并，key相同时value相加","date":"2018-03-31T16:00:00.000Z","path":"2018/04/01/scalaMapAdd/","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"}]},{"title":"scala 下划线使用指南","date":"2018-03-28T16:00:00.000Z","path":"2018/03/29/scalaUnderscoreUseGuide/","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"},{"name":"转载","slug":"转载","permalink":"https://dongkelun.com/tags/转载/"}]},{"title":"spark连接hive（spark-shell和eclipse两种方式）","date":"2018-03-24T16:00:00.000Z","path":"2018/03/25/sparkHive/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"hive","slug":"hive","permalink":"https://dongkelun.com/tags/hive/"}]},{"title":"centos7 hive 单机模式安装配置","date":"2018-03-23T16:00:00.000Z","path":"2018/03/24/hiveConf/","categories":[],"tags":[{"name":"hive","slug":"hive","permalink":"https://dongkelun.com/tags/hive/"},{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"}]},{"title":"centos7 hadoop 单机模式安装配置","date":"2018-03-22T16:00:00.000Z","path":"2018/03/23/hadoopConf/","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"},{"name":"hadoop","slug":"hadoop","permalink":"https://dongkelun.com/tags/hadoop/"}]},{"title":"连接mysql报错：Exception in thread \"main\" java.sql.SQLException:The server time zone value 'EDT' is unrecognized or represents more than one time zone","date":"2018-03-21T16:00:00.000Z","path":"2018/03/22/mysqlTimeZoneErr/","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://dongkelun.com/tags/mysql/"}]},{"title":"Spark Sql 连接mysql","date":"2018-03-20T16:00:00.000Z","path":"2018/03/21/sparkMysql/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"}]},{"title":"win10 spark+scala+eclipse+sbt 安装配置","date":"2018-03-14T16:00:00.000Z","path":"2018/03/15/winSparkConf/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"},{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"}]},{"title":"spark基本概念（便于自己随时查阅--摘自Spark快速大数据分析）","date":"2018-01-22T16:00:00.000Z","path":"2018/01/23/sparkBasicConcept/","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"https://dongkelun.com/tags/spark/"}]},{"title":"ibatis 事务 java","date":"2018-01-21T16:00:00.000Z","path":"2018/01/22/ibatisTransaction/","categories":[],"tags":[{"name":"ibatis","slug":"ibatis","permalink":"https://dongkelun.com/tags/ibatis/"},{"name":"java","slug":"java","permalink":"https://dongkelun.com/tags/java/"}]},{"title":"network is unreachable centos无法连接外网（或unknown host baidu.com）","date":"2018-01-16T16:00:00.000Z","path":"2018/01/17/networkIsUnreachable/","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"}]},{"title":"vmware centos7 设置固定ip","date":"2018-01-15T16:00:00.000Z","path":"2018/01/16/vmwareSetFixIP/","categories":[],"tags":[{"name":"vmware","slug":"vmware","permalink":"https://dongkelun.com/tags/vmware/"}]},{"title":"Redis Cluster 安装配置","date":"2018-01-08T16:00:00.000Z","path":"2018/01/09/redisClusterDeployment/","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://dongkelun.com/tags/redis/"}]}]