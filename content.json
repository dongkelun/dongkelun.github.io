[{"title":"Linux 安装 oh-my-zsh","date":"2018-12-28T16:00:00.000Z","path":"2018/12/29/linux-oh-my-zsh/","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://dongkelun.com/tags/Linux/"},{"name":"zsh","slug":"zsh","permalink":"https://dongkelun.com/tags/zsh/"}]},{"title":"Spark SQL 优化笔记","date":"2018-12-25T16:00:00.000Z","path":"2018/12/26/sparkSqlOptimize/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"SQL","slug":"SQL","permalink":"https://dongkelun.com/tags/SQL/"}]},{"title":"Scala学习笔记","date":"2018-12-13T16:00:00.000Z","path":"2018/12/14/scalaLearningNotes/","categories":[],"tags":[{"name":"Scala","slug":"Scala","permalink":"https://dongkelun.com/tags/Scala/"}]},{"title":"Hive分桶表学习总结","date":"2018-12-06T16:00:00.000Z","path":"2018/12/07/hiveBucketTable/","categories":[],"tags":[{"name":"Hive","slug":"Hive","permalink":"https://dongkelun.com/tags/Hive/"},{"name":"bucket","slug":"bucket","permalink":"https://dongkelun.com/tags/bucket/"}]},{"title":"Spark操作Hive分区表","date":"2018-12-03T16:00:00.000Z","path":"2018/12/04/sparkHivePatition/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Hive","slug":"Hive","permalink":"https://dongkelun.com/tags/Hive/"},{"name":"Partition","slug":"Partition","permalink":"https://dongkelun.com/tags/Partition/"}]},{"title":"Hive内部表和外部表","date":"2018-12-02T16:00:00.000Z","path":"2018/12/03/hiveInternalAndExternalTables/","categories":[],"tags":[{"name":"Hive","slug":"Hive","permalink":"https://dongkelun.com/tags/Hive/"}]},{"title":"Hive分区表学习总结","date":"2018-12-01T16:00:00.000Z","path":"2018/12/02/hivePartitionTable/","categories":[],"tags":[{"name":"Hive","slug":"Hive","permalink":"https://dongkelun.com/tags/Hive/"},{"name":"Partition","slug":"Partition","permalink":"https://dongkelun.com/tags/Partition/"}]},{"title":"Echarts中国地图三级钻取","date":"2018-11-26T16:00:00.000Z","path":"2018/11/27/echartsChinaMap/","categories":[],"tags":[{"name":"Echarts","slug":"Echarts","permalink":"https://dongkelun.com/tags/Echarts/"},{"name":"front-end","slug":"front-end","permalink":"https://dongkelun.com/tags/front-end/"}]},{"title":"打印（获取）HDFS路径下所有的文件名（包括子目录下的）","date":"2018-11-19T16:00:00.000Z","path":"2018/11/20/getAllHDFSFileNames/","categories":[],"tags":[{"name":"Scala","slug":"Scala","permalink":"https://dongkelun.com/tags/Scala/"},{"name":"HDFS","slug":"HDFS","permalink":"https://dongkelun.com/tags/HDFS/"}]},{"title":"通过Vue CLI 快速创建Vue项目并部署到tomcat","date":"2018-11-18T16:00:00.000Z","path":"2018/11/19/vueCliCreateProject/","categories":[],"tags":[{"name":"Vue","slug":"Vue","permalink":"https://dongkelun.com/tags/Vue/"},{"name":"Vue CLI","slug":"Vue-CLI","permalink":"https://dongkelun.com/tags/Vue-CLI/"}]},{"title":"Spark 通过 spark-submit 设置日志级别","date":"2018-11-15T16:00:00.000Z","path":"2018/11/16/sparkSubmitLogLevel/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"spark-submit","slug":"spark-submit","permalink":"https://dongkelun.com/tags/spark-submit/"}]},{"title":"Centos7 Tomcat9 安装笔记","date":"2018-10-22T16:00:00.000Z","path":"2018/10/23/tomcatConf/","categories":[],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"https://dongkelun.com/tags/tomcat/"}]},{"title":"Spark性能优化：基于分区进行操作","date":"2018-09-01T16:00:00.000Z","path":"2018/09/02/sparkMapPartitions/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Partitions","slug":"Partitions","permalink":"https://dongkelun.com/tags/Partitions/"},{"name":"性能优化","slug":"性能优化","permalink":"https://dongkelun.com/tags/性能优化/"}]},{"title":"利用Spark实现Oracle到Hive的历史数据同步","date":"2018-08-26T16:00:00.000Z","path":"2018/08/27/sparkOracle2Hive/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"},{"name":"Hive","slug":"Hive","permalink":"https://dongkelun.com/tags/Hive/"},{"name":"Oracle","slug":"Oracle","permalink":"https://dongkelun.com/tags/Oracle/"}]},{"title":"Spark通过修改DataFrame的schema给表字段添加注释","date":"2018-08-19T16:00:00.000Z","path":"2018/08/20/sparkDfAddComments/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"}]},{"title":"Spark创建空的DataFrame","date":"2018-08-13T16:00:00.000Z","path":"2018/08/14/sparkEmptyDataFrame/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"}]},{"title":"Spark 创建RDD、DataFrame各种情况的默认分区数","date":"2018-08-12T16:00:00.000Z","path":"2018/08/13/sparkDefaultPartitionNums/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"},{"name":"Partition","slug":"Partition","permalink":"https://dongkelun.com/tags/Partition/"},{"name":"Rdd","slug":"Rdd","permalink":"https://dongkelun.com/tags/Rdd/"}]},{"title":"Spark UDF使用详解及代码示例","date":"2018-08-01T16:00:00.000Z","path":"2018/08/02/sparkUDF/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"},{"name":"UDF","slug":"UDF","permalink":"https://dongkelun.com/tags/UDF/"}]},{"title":"通过数据库客户端界面工具DBeaver连接Hive","date":"2018-07-12T16:00:00.000Z","path":"2018/07/13/dbeaverConnectHive/","categories":[],"tags":[{"name":"界面工具","slug":"界面工具","permalink":"https://dongkelun.com/tags/界面工具/"},{"name":"hive","slug":"hive","permalink":"https://dongkelun.com/tags/hive/"}]},{"title":"ambari 异常总结及解决办法","date":"2018-07-09T16:00:00.000Z","path":"2018/07/10/ambariExceptions/","categories":[],"tags":[{"name":"ambari","slug":"ambari","permalink":"https://dongkelun.com/tags/ambari/"},{"name":"centos7","slug":"centos7","permalink":"https://dongkelun.com/tags/centos7/"}]},{"title":"HDFS DataNode启动异常:/opt/jdk1.8.0_151/bin/java:权限不够","date":"2018-07-09T16:00:00.000Z","path":"2018/07/10/HadoopException/","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://dongkelun.com/tags/Hadoop/"},{"name":"ambari","slug":"ambari","permalink":"https://dongkelun.com/tags/ambari/"}]},{"title":"spark-submit报错:Application application_1529650293575_0148 finished with failed status","date":"2018-07-05T16:00:00.000Z","path":"2018/07/06/sparkSubmitException1/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"spark-submit","slug":"spark-submit","permalink":"https://dongkelun.com/tags/spark-submit/"}]},{"title":"Spark DataFrame按某列降序排序","date":"2018-07-03T16:00:00.000Z","path":"2018/07/04/sparkDfSortDesc/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"}]},{"title":"Spark获取当前分区的partitionId","date":"2018-06-27T16:00:00.000Z","path":"2018/06/28/sparkGetPartitionId/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Partition","slug":"Partition","permalink":"https://dongkelun.com/tags/Partition/"}]},{"title":"SparkStreaming+Kafka 实现统计基于缓存的实时uv","date":"2018-06-24T16:00:00.000Z","path":"2018/06/25/KafkaUV/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"SparkStreaming","slug":"SparkStreaming","permalink":"https://dongkelun.com/tags/SparkStreaming/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"}]},{"title":"通过offsets.retention.minutes设置kafka offset的过期时间","date":"2018-06-20T16:00:00.000Z","path":"2018/06/21/modifyKafkaOffsetTime/","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"}]},{"title":"Spark Streaming+Kafka提交offset实现有且仅有一次(exactly-once)","date":"2018-06-19T16:00:00.000Z","path":"2018/06/20/sparkStreamingOffsetOnlyOnce/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"},{"name":"Spark Streaming","slug":"Spark-Streaming","permalink":"https://dongkelun.com/tags/Spark-Streaming/"}]},{"title":"spark-submit提交Spark Streaming+Kafka程序","date":"2018-06-18T16:00:00.000Z","path":"2018/06/19/sparkSubmitKafka/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"},{"name":"Spark Streaming","slug":"Spark-Streaming","permalink":"https://dongkelun.com/tags/Spark-Streaming/"},{"name":"spark-submit","slug":"spark-submit","permalink":"https://dongkelun.com/tags/spark-submit/"}]},{"title":"SparkStreaming+Kafka 实现基于缓存的实时wordcount程序","date":"2018-06-13T16:00:00.000Z","path":"2018/06/14/updateStateBykeyWordCount/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"SparkStreaming","slug":"SparkStreaming","permalink":"https://dongkelun.com/tags/SparkStreaming/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"}]},{"title":"Spark架构原理","date":"2018-06-08T16:00:00.000Z","path":"2018/06/09/sparkArchitecturePrinciples/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"原理","slug":"原理","permalink":"https://dongkelun.com/tags/原理/"}]},{"title":"Spark 持久化（cache和persist的区别）","date":"2018-06-02T16:00:00.000Z","path":"2018/06/03/sparkCacheAndPersist/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"持久化","slug":"持久化","permalink":"https://dongkelun.com/tags/持久化/"},{"name":"cache","slug":"cache","permalink":"https://dongkelun.com/tags/cache/"},{"name":"persist","slug":"persist","permalink":"https://dongkelun.com/tags/persist/"}]},{"title":"Scala日期操作","date":"2018-05-31T16:00:00.000Z","path":"2018/06/01/scalaDate/","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"},{"name":"日期","slug":"日期","permalink":"https://dongkelun.com/tags/日期/"}]},{"title":"Spark读取压缩文件","date":"2018-05-29T16:00:00.000Z","path":"2018/05/30/sparkGZ/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"压缩文件","slug":"压缩文件","permalink":"https://dongkelun.com/tags/压缩文件/"},{"name":"编码问题","slug":"编码问题","permalink":"https://dongkelun.com/tags/编码问题/"}]},{"title":"如何解决Spark开发中遇到需要去掉文件前几行数据的问题","date":"2018-05-26T16:00:00.000Z","path":"2018/05/27/sparkDelFirstNLines/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"rdd","slug":"rdd","permalink":"https://dongkelun.com/tags/rdd/"}]},{"title":"利用ogg实现oracle到kafka的增量数据实时同步","date":"2018-05-22T16:00:00.000Z","path":"2018/05/23/oggOracle2Kafka/","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"},{"name":"ogg","slug":"ogg","permalink":"https://dongkelun.com/tags/ogg/"}]},{"title":"Kafka安装启动入门教程","date":"2018-05-20T16:00:00.000Z","path":"2018/05/21/kafkaConf/","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"},{"name":"centos7","slug":"centos7","permalink":"https://dongkelun.com/tags/centos7/"}]},{"title":"hive查询报错:java.io.IOException:org.apache.parquet.io.ParquetDecodingException","date":"2018-05-19T16:00:00.000Z","path":"2018/05/20/hiveQueryException/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"hive","slug":"hive","permalink":"https://dongkelun.com/tags/hive/"},{"name":"异常解决","slug":"异常解决","permalink":"https://dongkelun.com/tags/异常解决/"}]},{"title":"Spark Streaming连接Kafka入门教程","date":"2018-05-16T16:00:00.000Z","path":"2018/05/17/sparkKafka/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Kafka","slug":"Kafka","permalink":"https://dongkelun.com/tags/Kafka/"},{"name":"Spark Streaming","slug":"Spark-Streaming","permalink":"https://dongkelun.com/tags/Spark-Streaming/"}]},{"title":"spark ML之特征处理（1）","date":"2018-05-16T16:00:00.000Z","path":"2018/05/17/sparkMlFeatureProcessing1/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"ml","slug":"ml","permalink":"https://dongkelun.com/tags/ml/"}]},{"title":"旧版Spark（1.6版本） 将RDD动态转为DataFrame","date":"2018-05-10T16:00:00.000Z","path":"2018/05/11/rdd2df/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"},{"name":"Rdd","slug":"Rdd","permalink":"https://dongkelun.com/tags/Rdd/"}]},{"title":"spark-submit报错:Exception in thread \"main\" java.sql.SQLException:No suitable driver","date":"2018-05-05T16:00:00.000Z","path":"2018/05/06/sparkSubmitException/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"spark-submit","slug":"spark-submit","permalink":"https://dongkelun.com/tags/spark-submit/"}]},{"title":"Centos7 安装oracle11","date":"2018-05-04T16:00:00.000Z","path":"2018/05/05/oracleConf/","categories":[],"tags":[{"name":"centos7","slug":"centos7","permalink":"https://dongkelun.com/tags/centos7/"},{"name":"oracle","slug":"oracle","permalink":"https://dongkelun.com/tags/oracle/"}]},{"title":"Spark 将DataFrame所有的列类型改为double","date":"2018-04-26T16:00:00.000Z","path":"2018/04/27/dfChangeAllColDatatypes/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"DataFrame","slug":"DataFrame","permalink":"https://dongkelun.com/tags/DataFrame/"}]},{"title":"centos7 ambari2.6.1.5+hdp2.6.4.0 大数据集群安装部署","date":"2018-04-24T16:00:00.000Z","path":"2018/04/25/ambariConf/","categories":[],"tags":[{"name":"ambari","slug":"ambari","permalink":"https://dongkelun.com/tags/ambari/"},{"name":"centos7","slug":"centos7","permalink":"https://dongkelun.com/tags/centos7/"}]},{"title":"spark on yarn 配置及异常解决","date":"2018-04-15T16:00:00.000Z","path":"2018/04/16/sparkOnYarnConf/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"yarn","slug":"yarn","permalink":"https://dongkelun.com/tags/yarn/"}]},{"title":"Spark 统计每天新增用户数","date":"2018-04-10T16:00:00.000Z","path":"2018/04/11/sparkNewUV/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Scala","slug":"Scala","permalink":"https://dongkelun.com/tags/Scala/"},{"name":"面试题","slug":"面试题","permalink":"https://dongkelun.com/tags/面试题/"}]},{"title":"spark ML算法之线性回归使用","date":"2018-04-08T16:00:00.000Z","path":"2018/04/09/sparkMlLinearRegressionUsing/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"ml","slug":"ml","permalink":"https://dongkelun.com/tags/ml/"},{"name":"算法","slug":"算法","permalink":"https://dongkelun.com/tags/算法/"}]},{"title":"centos7 hadoop 集群安装配置","date":"2018-04-04T16:00:00.000Z","path":"2018/04/05/hadoopClusterConf/","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://dongkelun.com/tags/Hadoop/"},{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"}]},{"title":"CentOS 初始环境配置","date":"2018-04-04T16:00:00.000Z","path":"2018/04/05/centosInitialConf/","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"}]},{"title":"linux ssh 免密登录","date":"2018-04-04T16:00:00.000Z","path":"2018/04/05/sshConf/","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://dongkelun.com/tags/linux/"}]},{"title":"scala 两个map合并，key相同时value相加","date":"2018-03-31T16:00:00.000Z","path":"2018/04/01/scalaMapAdd/","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"}]},{"title":"scala 下划线使用指南","date":"2018-03-28T16:00:00.000Z","path":"2018/03/29/scalaUnderscoreUseGuide/","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"https://dongkelun.com/tags/scala/"},{"name":"转载","slug":"转载","permalink":"https://dongkelun.com/tags/转载/"}]},{"title":"Spark连接Hive（spark-shell和Eclipse两种方式）","date":"2018-03-24T16:00:00.000Z","path":"2018/03/25/sparkHive/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"hive","slug":"hive","permalink":"https://dongkelun.com/tags/hive/"}]},{"title":"centos7 hive 单机模式安装配置","date":"2018-03-23T16:00:00.000Z","path":"2018/03/24/hiveConf/","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"},{"name":"hive","slug":"hive","permalink":"https://dongkelun.com/tags/hive/"}]},{"title":"centos7 hadoop 单机模式安装配置","date":"2018-03-22T16:00:00.000Z","path":"2018/03/23/hadoopConf/","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://dongkelun.com/tags/Hadoop/"},{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"}]},{"title":"连接mysql报错：Exception in thread \"main\" java.sql.SQLException:The server time zone value 'EDT' is unrecognized or represents more than one time zone","date":"2018-03-21T16:00:00.000Z","path":"2018/03/22/mysqlTimeZoneErr/","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://dongkelun.com/tags/mysql/"}]},{"title":"Spark Sql 连接mysql","date":"2018-03-20T16:00:00.000Z","path":"2018/03/21/sparkMysql/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Scala","slug":"Scala","permalink":"https://dongkelun.com/tags/Scala/"}]},{"title":"win10 spark+scala+eclipse+sbt 安装配置","date":"2018-03-14T16:00:00.000Z","path":"2018/03/15/winSparkConf/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"},{"name":"Scala","slug":"Scala","permalink":"https://dongkelun.com/tags/Scala/"}]},{"title":"Spark基本概念（便于自己随时查阅--摘自Spark快速大数据分析）","date":"2018-01-22T16:00:00.000Z","path":"2018/01/23/sparkBasicConcept/","categories":[],"tags":[{"name":"Spark","slug":"Spark","permalink":"https://dongkelun.com/tags/Spark/"}]},{"title":"ibatis 事务 java","date":"2018-01-21T16:00:00.000Z","path":"2018/01/22/ibatisTransaction/","categories":[],"tags":[{"name":"ibatis","slug":"ibatis","permalink":"https://dongkelun.com/tags/ibatis/"},{"name":"java","slug":"java","permalink":"https://dongkelun.com/tags/java/"}]},{"title":"network is unreachable centos无法连接外网（或unknown host baidu.com）","date":"2018-01-16T16:00:00.000Z","path":"2018/01/17/networkIsUnreachable/","categories":[],"tags":[{"name":"centos","slug":"centos","permalink":"https://dongkelun.com/tags/centos/"}]},{"title":"vmware centos7 设置固定ip","date":"2018-01-15T16:00:00.000Z","path":"2018/01/16/vmwareSetFixIP/","categories":[],"tags":[{"name":"vmware","slug":"vmware","permalink":"https://dongkelun.com/tags/vmware/"}]},{"title":"Redis Cluster 安装配置","date":"2018-01-08T16:00:00.000Z","path":"2018/01/09/redisClusterDeployment/","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://dongkelun.com/tags/redis/"}]}]